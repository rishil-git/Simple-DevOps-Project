{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishil-git/Simple-DevOps-Project/blob/master/001_Prompt_Eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \\\n",
        "  openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxodq3jKb3ww",
        "outputId": "1d8f2c0b-474c-4539-a60a-9fbc2412e1b1"
      },
      "id": "Fxodq3jKb3ww",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5",
      "metadata": {
        "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5"
      },
      "source": [
        "# Guidelines for Prompting\n",
        "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
        "\n",
        "## Setup\n",
        "#### Load the API key and relevant Python libaries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00bab499-9a50-4bd0-a622-1c914c6ccc29",
      "metadata": {
        "id": "00bab499-9a50-4bd0-a622-1c914c6ccc29"
      },
      "source": [
        "In this course, we've provided some code that loads the OpenAI API key for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c382975",
      "metadata": {
        "height": 132,
        "tags": [],
        "id": "6c382975"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3acefa8-f8f1-4ef8-932e-9bcefa142666",
      "metadata": {
        "id": "a3acefa8-f8f1-4ef8-932e-9bcefa142666"
      },
      "source": [
        "#### helper function\n",
        "Throughout this course, we will use OpenAI's `gpt-4o` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "998atyZigdLF"
      },
      "id": "998atyZigdLF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  response = openai_client.chat.completions.create(\n",
        "      model='gpt-4o',\n",
        "      messages=[{\n",
        "          \"role\":\"user\",\n",
        "          \"content\":\"How Are you today ?\"\n",
        "      }\n",
        "\n",
        "      ]\n",
        "  )\n",
        "  print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "KZzGW8ZFWzXv",
        "outputId": "cc8e3deb-5a97-4394-ff8a-687d889d699e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KZzGW8ZFWzXv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thank you for asking! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7dff174",
      "metadata": {
        "height": 149,
        "tags": [],
        "id": "a7dff174"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-4o\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b62298e-2181-4e73-bb40-77e20c655231",
      "metadata": {
        "id": "3b62298e-2181-4e73-bb40-77e20c655231"
      },
      "source": [
        "## Prompting Principles\n",
        "- **Principle 1: Write clear and specific instructions**\n",
        "- **Principle 2: Give the model time to “think”**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Principle 1 Tactics\n",
        "\n",
        "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`"
      ],
      "metadata": {
        "id": "8fqquNjbf4HP"
      },
      "id": "8fqquNjbf4HP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87121316",
      "metadata": {
        "height": 336,
        "tags": [],
        "id": "87121316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c5dc02-8e97-44f3-d5e6-9e357ffb8b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CTX-214 Phase III trial, conducted over 24 weeks across 15 global sites, demonstrated a statistically significant reduction in HbA1c in 400 patients with Type 2 Diabetes, with no serious adverse events reported.\n"
          ]
        }
      ],
      "source": [
        "pharma_text = \"\"\"\n",
        "CTX-214 Phase III trial evaluated efficacy and safety in 400 patients with Type 2 Diabetes.\n",
        "The study spanned 15 global sites and lasted 24 weeks.\n",
        "Primary endpoint: Reduction in HbA1c.\n",
        "Results: Statistically significant improvement with no serious adverse events reported.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a clinical research analyst.\n",
        "Summarize the information between the <trial> tags below into a single sentence\n",
        "focusing on: drug/trial name, indication, patient count, duration, outcome, and safety.\n",
        "\n",
        "---\n",
        "<trial>\n",
        "{pharma_text}\n",
        "</trial>\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2798f3d-7618-4ac5-a6b2-3c69c537903d",
      "metadata": {
        "id": "f2798f3d-7618-4ac5-a6b2-3c69c537903d"
      },
      "source": [
        "#### Tactic 2: Ask for a structured output\n",
        "- JSON, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b50bbbd",
      "metadata": {
        "height": 149,
        "tags": [],
        "id": "6b50bbbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2270f6-a16a-4991-b667-5d754e6665dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"drug_id\": \"RX001\",\n",
            "        \"name\": \"CardioRelief\",\n",
            "        \"manufacturer\": \"HealthGenix Pharmaceuticals\",\n",
            "        \"therapeutic_area\": \"Cardiovascular Health\"\n",
            "    },\n",
            "    {\n",
            "        \"drug_id\": \"RX002\",\n",
            "        \"name\": \"NeuroCalm\",\n",
            "        \"manufacturer\": \"NeuroPharm Solutions\",\n",
            "        \"therapeutic_area\": \"Neurology\"\n",
            "    },\n",
            "    {\n",
            "        \"drug_id\": \"RX003\",\n",
            "        \"name\": \"GastroEase\",\n",
            "        \"manufacturer\": \"DigestiveCare Inc.\",\n",
            "        \"therapeutic_area\": \"Gastroenterology\"\n",
            "    }\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "output_format = \"JSON\"\n",
        "prompt = f\"\"\"\n",
        "Generate a list of three fictional pharmaceutical drugs \\\n",
        "along with their manufacturers and therapeutic areas.\n",
        "Provide them in {output_format} format with the following keys:\n",
        "drug_id, name, manufacturer, therapeutic_area.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d",
      "metadata": {
        "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d"
      },
      "source": [
        "#### Tactic 3: Ask the model to check whether conditions are satisfied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ae612e",
      "metadata": {
        "height": 506,
        "tags": [],
        "id": "f0ae612e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea37b8da-b8fb-4591-d869-84adfe5c2b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Screening visit to determine subject eligibility, including medical history and laboratory tests.  \n",
            "Step 2 - Enter a 2-week washout period where any previous medications are discontinued.  \n",
            "Step 3 - Receive the first dose of the investigational drug under supervision.  \n",
            "Step 4 - Monitor vital signs every 30 minutes for the next 4 hours.  \n",
            "Step 5 - Return for follow-up visits on Days 7, 14, and 28 to assess safety and efficacy.\n"
          ]
        }
      ],
      "source": [
        "text_1 = f\"\"\"\n",
        "The clinical trial began with a screening visit to determine subject eligibility,\n",
        "including medical history and laboratory tests. Upon passing the screening,\n",
        "participants entered a 2-week washout period where any previous medications were discontinued.\n",
        "After the washout, subjects received the first dose of the investigational drug under supervision.\n",
        "Vital signs were monitored every 30 minutes for the next 4 hours.\n",
        "Subjects then returned for follow-up visits on Days 7, 14, and 28 to assess safety and efficacy.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You will be provided with clinical procedure text delimited by triple quotes.\n",
        "If it contains a sequence of procedural steps, re-write them in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - ...\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of steps or instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76b6cc59",
      "metadata": {
        "height": 506,
        "tags": [],
        "id": "76b6cc59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50becec-4789-4d84-ac9f-d31ef58a0815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ],
      "source": [
        "text_2 = f\"\"\"\n",
        "The clinical trial results were promising, with a significant reduction in blood pressure\n",
        "observed in the treatment group. Participants reported minimal side effects, and\n",
        "overall tolerability was high. The study was conducted across multiple sites and\n",
        "included a diverse patient population. Investigators noted improvements in adherence\n",
        "and patient-reported outcomes, especially among those who had previously shown resistance\n",
        "to standard antihypertensive therapies.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \"No steps provided.\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5866b8-d8c7-4e19-93db-401315f64954",
      "metadata": {
        "id": "3c5866b8-d8c7-4e19-93db-401315f64954"
      },
      "source": [
        "#### Tactic 4: \"Few-shot\" prompting\n",
        "Few-shot prompting helps bridge the gap between what a large language model (LLM) can do and what you want it to do, without **fine-tuning**.\n",
        "\n",
        "Large Language Models (LLMs) like GPT-4 are trained on a vast general corpus (Wikipedia, GitHub, books, etc.), but:\n",
        "```\n",
        "  •\tThey may not fully understand specialized business terms (e.g., pharma, finance, legal).\n",
        "  \n",
        "  •\tThey might misinterpret task-specific intents (e.g., how you want to classify a complaint or triage a support ticket).\n",
        "```\n",
        "\n",
        "Two-shot prompting is useful when the model needs guidance through multiple diverse examples to generalize a task better, especially in ambiguous or domain-specific contexts. It strikes a balance between zero-shot simplicity and few-shot specificity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ce1540",
      "metadata": {
        "height": 251,
        "tags": [],
        "id": "82ce1540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4bfdfb-9961-40b1-d826-799ea07241cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adverse Event\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a medical triage assistant. Read each HCP query and classify it into one of the following:\n",
        "[\"Adverse Event\", \"Product Inquiry\", \"Off-label Use Inquiry\", \"Medical Literature Request\", \"Clinical Trial Request\", \"Other\"]\n",
        "\n",
        "Examples:\n",
        "\n",
        "Q: \"Patient developed severe rash after starting DrugX. Is this expected?\"\n",
        "A: Adverse Event\n",
        "\n",
        "Q: \"Can you provide the mechanism of action of DrugY?\"\n",
        "A: Product Inquiry\n",
        "\n",
        "Q: \"Is DrugZ effective in pediatric patients with rheumatoid arthritis?\"\n",
        "A: Off-label Use Inquiry\n",
        "\n",
        "Q: \"Please send me publications related to DrugA's efficacy in migraines.\"\n",
        "A: Medical Literature Request\n",
        "\n",
        "Q: \"How do I enroll my patients into the ongoing phase 3 trial for DrugB?\"\n",
        "A: Clinical Trial Request\n",
        "\n",
        "Q: \"Where can I find pricing information for DrugC?\"\n",
        "A: Other\n",
        "\n",
        "Now classify the following:\n",
        "\n",
        "Q: \"My patient experienced dizziness after taking the first dose of DrugP. Should I report it?\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10",
      "metadata": {
        "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10"
      },
      "source": [
        "### Principle 2: Give the model time to “think”\n",
        "\n",
        "#### Tactic 1: Specify the steps required to complete a task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7d6860",
      "metadata": {
        "height": 506,
        "tags": [],
        "id": "5e7d6860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0a132c-f829-473d-d75b-edcd07eaf514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "1 - Summary: A Phase IIb study of GLX-108 in 280 asthma patients showed significant lung function improvement and a favorable safety profile.\n",
            "\n",
            "2 - Spanish Translation: Un estudio de fase IIb de GLX-108 en 280 pacientes con asma mostró una mejora significativa en la función pulmonar y un perfil de seguridad favorable.\n",
            "\n",
            "3 - Drug Names: GLX-108\n",
            "\n",
            "4 - JSON Object:\n",
            "```json\n",
            "{\n",
            "  \"spanish_summary\": \"Un estudio de fase IIb de GLX-108 en 280 pacientes con asma mostró una mejora significativa en la función pulmonar y un perfil de seguridad favorable.\",\n",
            "  \"drug_names\": [\"GLX-108\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "clinical_trial_text = f\"\"\"\n",
        "A recent Phase IIb study evaluated the investigational drug GLX-108 in 280 patients with moderate-to-severe asthma.\n",
        "The randomized, double-blind trial was conducted over 16 weeks across 12 sites in Europe.\n",
        "Primary outcome: improvement in FEV1 (forced expiratory volume).\n",
        "The trial met its endpoint, showing a significant improvement in lung function with a favorable safety profile.\n",
        "\"\"\"\n",
        "\n",
        "# Pharma-style multi-step prompt\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following clinical trial text (delimited by triple backticks) into a single sentence.\n",
        "2 - Translate the summary into Spanish.\n",
        "3 - List each drug or compound name mentioned in the Spanish summary.\n",
        "4 - Output a JSON object with the following keys: spanish_summary, drug_names.\n",
        "\n",
        "Text:\n",
        "```{clinical_trial_text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0bb1dcf-95f5-4ee1-8c25-8b2abd5f0f0d",
      "metadata": {
        "id": "d0bb1dcf-95f5-4ee1-8c25-8b2abd5f0f0d"
      },
      "source": [
        "#### Ask for output in a specified format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4222cc",
      "metadata": {
        "height": 370,
        "tags": [],
        "id": "3e4222cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf29bff-ccff-4d59-983e-2a25dee70976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt:\n",
            "Summary: The Phase III trial of Lorafenib by BioThera showed a 32% improvement in progression-free survival for late-stage melanoma patients without new safety concerns.\n",
            "\n",
            "Translation: L'essai de phase III de Lorafenib par BioThera a montré une amélioration de 32 % de la survie sans progression pour les patients atteints de mélanome à un stade avancé sans nouveaux problèmes de sécurité.\n",
            "\n",
            "Names: Lorafenib, BioThera\n",
            "\n",
            "Output JSON: {\n",
            "  \"summary\": \"L'essai de phase III de Lorafenib par BioThera a montré une amélioration de 32 % de la survie sans progression pour les patients atteints de mélanome à un stade avancé sans nouveaux problèmes de sécurité.\",\n",
            "  \"num_names\": 2,\n",
            "  \"schema\": [\n",
            "    {\n",
            "      \"field\": \"summary\",\n",
            "      \"description\": \"French translated summary of the original text.\",\n",
            "      \"datatype\": \"string\"\n",
            "    },\n",
            "    {\n",
            "      \"field\": \"num_names\",\n",
            "      \"description\": \"Total count of identified proper names in the French summary.\",\n",
            "      \"datatype\": \"integer\"\n",
            "    },\n",
            "    {\n",
            "      \"field\": \"schema\",\n",
            "      \"description\": \"A list of dictionaries describing each field in the JSON object.\",\n",
            "      \"datatype\": \"list\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Define clinical text input\n",
        "text = f\"\"\"\n",
        "The Phase III trial of the drug Lorafenib, developed by BioThera, enrolled 600 patients with late-stage melanoma.\n",
        "The study demonstrated a 32% improvement in progression-free survival compared to the control arm.\n",
        "No new safety concerns were identified during the 18-month follow-up.\n",
        "\"\"\"\n",
        "\n",
        "# Define multi-step prompt\n",
        "prompt = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by < > using a single concise sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - Identify all proper names (e.g., drug names, companies, or diseases) in the French summary.\n",
        "4 - Output a JSON object with the following fields:\n",
        "   - summary: French translated summary\n",
        "   - num_names: total count of identified names\n",
        "   - schema: a list of dictionaries describing each field in the JSON, containing:\n",
        "     * field: the field name\n",
        "     * description: explanation of what the field contains\n",
        "     * datatype: data type (e.g., string, integer)\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of proper names in French summary>\n",
        "Output JSON: <json with summary, num_names, schema<field_of_json, description_of_field, datatype>>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "\n",
        "# Call your completion function (assume get_completion uses OpenAI or similar)\n",
        "response = get_completion(prompt)\n",
        "print(\"\\nCompletion for prompt:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad",
      "metadata": {
        "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad"
      },
      "source": [
        "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5cc985",
      "metadata": {
        "height": 421,
        "tags": [],
        "id": "ff5cc985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0ecc26-7c0f-4220-ebdb-237ca1dbe0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is correct. The total cost for the first year of operations as a function of the number of square feet \\( x \\) is calculated as follows:\n",
            "\n",
            "1. **Land cost**: \\( 100x \\) (since land costs $100 per square foot)\n",
            "2. **Solar panel cost**: \\( 250x \\) (since solar panels cost $250 per square foot)\n",
            "3. **Maintenance cost**: \\( 100,000 + 10x \\) (a flat $100,000 per year plus $10 per square foot)\n",
            "\n",
            "Adding these costs together gives:\n",
            "\n",
            "\\[\n",
            "100x + 250x + 100,000 + 10x = 360x + 100,000\n",
            "\\]\n",
            "\n",
            "It seems there was a mistake in the student's solution regarding the maintenance cost per square foot. The correct maintenance cost should be \\( 10x \\) instead of \\( 100x \\). Therefore, the correct total cost should be:\n",
            "\n",
            "\\[\n",
            "360x + 100,000\n",
            "\\]\n",
            "\n",
            "The student's solution incorrectly calculated the maintenance cost per square foot, leading to an incorrect total cost expression.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a",
      "metadata": {
        "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a"
      },
      "source": [
        "#### Note that the student's solution is actually not correct.\n",
        "#### We can fix this by instructing the model to work out its own solution first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703f7003",
      "metadata": {
        "height": 999,
        "tags": [],
        "id": "703f7003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa284c1d-98a9-4dd2-9cec-d45268cbce8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```\n",
            "Let x be the size of the installation in square feet.\n",
            "Costs:\n",
            "1. Land cost: 100x (since land costs $100 per square foot)\n",
            "2. Solar panel cost: 250x (since solar panels cost $250 per square foot)\n",
            "3. Maintenance cost: 100,000 + 10x (since the maintenance costs a flat $100k per year plus $10 per square foot)\n",
            "\n",
            "Total cost for the first year of operations:\n",
            "= Land cost + Solar panel cost + Maintenance cost\n",
            "= 100x + 250x + (100,000 + 10x)\n",
            "= 100x + 250x + 100,000 + 10x\n",
            "= 360x + 100,000\n",
            "```\n",
            "Is the student's solution the same as actual solution just calculated:\n",
            "```\n",
            "no\n",
            "```\n",
            "Student grade:\n",
            "```\n",
            "incorrect\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a207eab-a1b1-47a5-b913-fe38086123d0",
      "metadata": {
        "id": "8a207eab-a1b1-47a5-b913-fe38086123d0"
      },
      "source": [
        "## Model Limitations: Hallucinations\n",
        "- Boie is a real company, the product name is not real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c80919",
      "metadata": {
        "height": 98,
        "tags": [],
        "id": "81c80919"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea88a6e-0141-4296-a73b-6b2282fe0de6",
      "metadata": {
        "id": "eea88a6e-0141-4296-a73b-6b2282fe0de6"
      },
      "source": [
        "## Try experimenting on your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77457878",
      "metadata": {
        "height": 30,
        "id": "77457878"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}